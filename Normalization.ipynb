{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Rwz4id1cvk0PhAQoYKlqpnyIQAjXp8CQ",
      "authorship_tag": "ABX9TyNWgM1JxldaYKkcy8gBMSfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chjohnso-um/chjohnso-um-CSC-587/blob/main/Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "A9gHILKdowbf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove columns with 50% or more missing values"
      ],
      "metadata": {
        "id": "KY3CRzQarN-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Drop columns where 50% or more values are missing\n",
        "threshold = len(df) * 0.5\n",
        "df_cleaned = df.dropna(axis=1, thresh=threshold)\n",
        "\n",
        "# Optionally, save the cleaned DataFrame to a new file\n",
        "df_cleaned.to_csv('insert_name', index=False)\n"
      ],
      "metadata": {
        "id": "K8wr7TcJrLZO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Remove columns that the the BL and V06 data do not share"
      ],
      "metadata": {
        "id": "VVZI1kZVyCLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the two cleaned CSV files from previous step\n",
        "df1 = pd.read_csv('your_file1.csv')\n",
        "df2 = pd.read_csv('your_file2.csv')\n",
        "\n",
        "# Find common columns between the two DataFrames\n",
        "common_cols = df1.columns.intersection(df2.columns)\n",
        "\n",
        "# Keep only the common columns\n",
        "df1_common = df1[common_cols]\n",
        "df2_common = df2[common_cols]\n",
        "\n",
        "# Save to new CSV files\n",
        "df1_common.to_csv('insert_name1.csv', index=False)\n",
        "df2_common.to_csv('insert_name2.csv', index=False)\n"
      ],
      "metadata": {
        "id": "09YTURLiyJjb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fill empty cells with the columns median value"
      ],
      "metadata": {
        "id": "BqMj4e132y1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your DataFrame (example with one file, repeat if needed)\n",
        "df = pd.read_csv('saved_file_from_last_step')\n",
        "\n",
        "# Fill missing values in each column with its median\n",
        "df_filled = df.fillna(df.median(numeric_only=True))\n",
        "\n",
        "# Save the result to a new CSV (or overwrite)\n",
        "df_filled.to_csv('insert_name', index=False)\n"
      ],
      "metadata": {
        "id": "T-FvIQeb28Vc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Two-way normalization of the datasets. Quantile for the rows and z-score normalization for the columns."
      ],
      "metadata": {
        "id": "ihF93Sxe8sqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('your_imputed_file.csv')\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Convert numeric columns to float (prevents dtype warnings)\n",
        "df[numeric_cols] = df[numeric_cols].astype(float)\n",
        "\n",
        "# 1. Quantile Normalization (row-wise)\n",
        "def quantile_normalize(df_input):\n",
        "    # Sort each row and take the mean for each rank\n",
        "    sorted_df = pd.DataFrame(\n",
        "        np.sort(df_input.values, axis=1),\n",
        "        index=df_input.index,\n",
        "        columns=df_input.columns\n",
        "    )\n",
        "    rank_means = sorted_df.mean(axis=0).values\n",
        "\n",
        "    # Replace values by rank means\n",
        "    normalized = df_input.copy()\n",
        "    for i in range(df_input.shape[0]):\n",
        "        ranks = rankdata(df_input.iloc[i, :], method='min') - 1  # 0-based index\n",
        "        normalized.iloc[i, :] = [rank_means[r] for r in ranks]\n",
        "\n",
        "    return normalized\n",
        "\n",
        "# Apply quantile normalization\n",
        "df_quantile = quantile_normalize(df[numeric_cols])\n",
        "\n",
        "# 2. Z-score Normalization (column-wise)\n",
        "df_zscore = (df_quantile - df_quantile.mean()) / df_quantile.std()\n",
        "\n",
        "# Reattach non-numeric columns\n",
        "df_final = pd.concat([df[non_numeric_cols].reset_index(drop=True), df_zscore.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Save the final output\n",
        "df_final.to_csv('normalized_quantile_file.csv', index=False)"
      ],
      "metadata": {
        "id": "1H9aDGPE9E0n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Two-way normalization of the datasets. Sum-to-1 for the rows and z-score normalization for the columns."
      ],
      "metadata": {
        "id": "TTO3YQGHHtg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "df = pd.read_csv('your_imputed_file.csv')\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Convert numeric to float (to avoid warnings and support division)\n",
        "df[numeric_cols] = df[numeric_cols].astype(float)\n",
        "\n",
        "# 1. Row-wise sum-to-1 normalization\n",
        "df_sum1 = df[numeric_cols].div(df[numeric_cols].sum(axis=1), axis=0)\n",
        "\n",
        "# 2. Column-wise z-score normalization\n",
        "df_zscore = (df_sum1 - df_sum1.mean()) / df_sum1.std()\n",
        "\n",
        "# Reattach non-numeric columns\n",
        "df_final = pd.concat([df[non_numeric_cols].reset_index(drop=True), df_zscore.reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Save the final result\n",
        "df_final.to_csv('normalized_sum_file.csv', index=False)\n"
      ],
      "metadata": {
        "id": "YCmbLiSWHx9V"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}